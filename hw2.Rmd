---
output: html_document
---
#HW 2 - La Quinta is Spanish for Next to Denny's#
Team 4 - Duke Dinosaurs    
Due: Oct 14, 2015  

##La Quinta##
There are two steps to scraping all the LaQuintas' across the United States. First we need a `get_lq.R` file which downloads all the htmls of the LaQuintas across the United States. Then we need a `parse_lq.R` file which searches the individual htmls for the appropriate information. 

On the most rudimentary level, the `get_lq.R` file uses two commands to download the htmls. First, we need to specify a `base_url`. The `base_url` is the top-most level--"www.lq.com"--that R needs to know. When we define this `base_url`, R will access the specified url to execute the next command. The next line, `listings_page`, will go to a secondary level from the `base_url`. Thus, in our case, R will go to this page: "http://www.lq.com/en/findandbook/hotel-listings.html." From here, we identified a .csv file that had the list of States with at least one LaQuinta, namely `lq_states.csv`. Then, in order to download the respective htmls of all the LaQuintas in each state, we utilized the function `get_state_hotels.` This function calls the `lq_states.csv` file and runs a loop for each State specified in the file thereby downloading all the corresponding htmls from the list of all the LaQuintas in the United States.  In order to prevent the LaQuinta homepage from blocking our download call, we implemented the "Sys.sleep(5)" command, which allowed for a 5 second lapse between each download call. Thus our `get_lq.R` function downloads all the htmls of the LaQuintas in the United States. 

Once we have downloaded all the htmls off of LaQuinta's webpage, we then want to parse through the htmls to compile the necessary information such as the address of the hotel, latitude and longitude, availability of internet, free parking, free complementary breakfast, swimming pools and etc. We were able to compile the information with by using selectorgadget on each of the individual hotel's pages. For example, if we want to know the above-mentioned information on LaQuinta's Durham-Chapel Hill location, we specified third level--the individual hotel's webpage--from the `listings_page`. Hence, to figure out the amenities in LaQuinta's Durham-Chapel Hill location, R will scrape the information from this page: "http://www.lq.com/en/findandbook/hotel-details.durham-chapel-hill.address.html". We used selectorgadget to pull the address, city, latitude, longitude and amenities. In order to construct a dataframe, we first specified a null dataframe to plug values into. Then we ran a loop to plug in the information that we scraped off of each hotel page. Then in the end, we used the rbind command to combine the rows into one dataframe `lq_final`.    
##Denny's##
To obtain all the Denny's locations in the US, we started by using a website called freemaptools to draw circles around parts of the US. With five circles, we should be covering all of US.
  
```
   Longitude Latitude Radius.Miles
1 -113.90625 40.64997          788
2  -95.44922 38.01140          851
3  -84.90234 38.88282         1056
4 -157.14844 20.82924          438
5 -141.67969 59.06586         1053
```
The first two columns tells us where the center of our circles are located. Radius.Miles tells us the radius of our circles in miles. These coordinates and radii will be stored in dennys_coords.csv so it can be used in the next steps.   
   
Now, in `get_dennys.R`, we'll extract the location data from `hosted.where2getit.com/dennys`. We get the locations in such a way because Denny's uses the third-party Where2GetIt API to display their restaurant locations. It will take the circle centers and radii specified in `dennys_coords.csv` to search for all locations within the radius of that circumference. We first specified the key, which Denny's uses, to access Where2GetIt API. Next, we limited the number of results to be 1,000. Now, `dennys_coords.csv` will have the longitude and latitude of the circle centers, as well as the search radius. Since we have five circles, we will run through the function five times using a ForLoop. The information will be stored as an .xml file under the dennys directory inside our data directory.    
   
Finally, we can construct a data frame with the details of each denny's location. We'll find the longitude, latitude, postal code, address, city, country, state, and unique id of each location. Since our circles overlap, we may have some locations listed multiple times. We'll use `unique` so that we only have each location listed once.    
Now that we have information on all Denny's locations in the US, it's possible to do distance analysis.    

##Distance Analysis##
For our Distance Analysis, we first need to decide how we are going to calculate distance. We've decided to use the Haversine Formula. This formula is used to calculate the distances between two points on a sphere where the path will go along the surface of the sphere. Instead of the Euclidean distance, the formula will give us the great-circle distance. Although Earth is not a sphere, for our purposes, it is enough to approximate it to be a sphere with a radius of 3,959 miles.    
We start with two points on earth. We want their longitudes and latitudes. We can then calculate the distance by 
The nearest Denny's for a La Quinta, but that La Quinta may not be the nearest La Quinta to that Denny's. This creates a discrepancy. Suppose we have an American Map, Denny's are x's and La Quinta are .'s. Approximating the numbers, we can see the distributions of both. They may not be evenly distributed. La Quinta's distribution may be more spread. Which is more densely distributed. It depends on what part of the US. Average of each tells us how clustered each store is. Can also plot density of each. Variance could differ. Analyze densities and variance which will indicate the clustering properties of each. 

Let's produce a map of the US's mainland. So all states except for Hawaii and Alaska. We can do this using the packages `maps` and `mapdata`. 
```{r}

load("data/dennys.Rdata") # loads dennys_df #
load("data/lq.Rdata") # loads lq_df #

d_coord <- data.frame(latitude= dennys_df$Latitude,longitude=dennys_df$Longitude) %>% dataframe_tolist()
l_coord <- data.frame(latitude= lq_df$Latitude,longitude=lq_df$Longitude)  %>% dataframe_tolist()

dist <- function(this, that){
  min_dist <- Inf
  for(i in that){
    temp_dist <- spatial_dist(this[1],this[2],i[1],i[2])
    if(temp_dist < min_dist){
      min_dist <- temp_dist
    }
  }
  return (c(this,min_dist))
}

spatial_dist <- function(thisx,thisy,thatx,thaty){
  # x is latitude, y is longitude #
  R = 3959 # Earth's radius in miles #
  radians = function(degrees) return(degrees*pi/180)
  # turns lat, long degrees into radians #
  this_lat = radians(thisx)
  this_long = radians(thisy)
  that_lat = radians(thatx)
  that_long = radians(thaty)
  # change lat and long to radians #
  a = (sin((that_lat - this_lat)/2))^2
  b = cos(this_lat)*cos(that_lat)*(sin((that_long - this_long)/2))^2
  d = 2*R*asin(sqrt(a+b)) # haversine formula #
  return(d) # distance between this and that #
}

dataframe_tolist <- function(frame){
  #Chun: put your dataframe to list conversion here
  return()
}

dennys_dist <- lapply(d_coord, dist(d_coord,l_coord))
do.call(rbind, dennys_dist)

lq_dist <- lapply(l_coord, dist(l_coord,d_coord))
do.call(rbind, lq_dist)


```

